{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dnn-hy 实验三 by 孟\n",
    "\n",
    "针对 origin_airport 和 dest_airport 进行降维，降维方法采用自然语言处理中的 embedding 方法，即将地址名称转变成多维度的量值表示，比如 机场 AMC to [0.5,1.22,3.44,2.8] 这样4维的表示。embedding 后 dot，最后 concate 上天气等信息，形成了一个 end-to-end 的模型， 准确率 70.1%, 并没有质的提升。\n",
    "\n",
    "先前步骤相同\n",
    "\n",
    "在 one_hot 编码时没有将 origin_airport 和 dest_airport 编码， 而是将机场名称转变成特定数字表示，比如 AMC 1, DEP 2\n",
    "这样， 剩下的改变都在模型上体现，也就是 embedding + dot 的网络结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from keras import initializers\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Input, Dense, Dropout, Dot, Concatenate, BatchNormalization\n",
    "from keras.layers.core import Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import concatenate\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_feather('/home/ubuntu/data/flight_data_7_18.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['feat1'] = data['delay_cat'].map(lambda x: 1 if x == '[-500,30)' or x == '[30,60)' or x == '[60,90)' or x == '[90,120)' else 0)\n",
    "data['feat2'] = data['feat1'].map(lambda x: 1-x)\n",
    "data = data.drop(['delay_cat'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "#data = shuffle(data)\n",
    "data = data.sample(frac=0.5)\n",
    "#print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "data_majority = data[data.feat1==1]\n",
    "data_minority = data[data.feat1==0]\n",
    "data_majority_downsampled = resample(data_majority,\n",
    "                                     replace=False,    # sample without replacement\n",
    "                                     n_samples=226020,     # to match minority class\n",
    "                                     random_state=1) # reproducible results\n",
    "data_downsampled = pd.concat([data_majority_downsampled, data_minority])\n",
    "data = data_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sch_time_year'] = data['sch_dep_time'].map(lambda x: x.year)\n",
    "data['sch_time_month'] = data['sch_dep_time'].map(lambda x: x.month)\n",
    "data['sch_time_day'] = data['sch_dep_time'].map(lambda x: x.day)\n",
    "data['sch_time_hour'] = data['sch_dep_time'].map(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sch_time_year'] = (data['sch_time_year'].map(lambda x: int(str(x)[2:])))\n",
    "month_num = {1:6, 2:2, 3:2, 4:5, 5:0, 6:3, 7:5, 8:1, 9:4, 10:6, 11:2, 12:4}\n",
    "data['year_num'] = data['sch_time_year'].map(lambda x: (int(x / 4) + x) % 7)\n",
    "data['month_num']=  data['sch_time_month'].map(lambda x: month_num[x])\n",
    "data['day_num'] = data['sch_time_day']\n",
    "data['sch_time_day'] = data.apply(lambda x: (x['year_num'] + x['month_num'] + x['day_num'])%7, axis=1)\n",
    "time_drop = ['year_num', 'month_num', 'day_num']\n",
    "data = data.drop(time_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sch_time_hour'] = data['sch_time_hour'].map(lambda x: 24 if x==0 else x)\n",
    "for i in range(8):  #每3个小时一个区间\n",
    "    data['sch_time_hour'] = data['sch_time_hour'].map(lambda x: 0+i if x>0+3*i and x<=3+3*i else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = ['feat1','feat2']\n",
    "label = data[lb]\n",
    "data = data.drop(lb, axis=1)\n",
    "data = data.drop('sch_dep_time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.iloc[:,3:24]\n",
    "\n",
    "data2 = data.iloc[:,0:3]\n",
    "data3 = data.iloc[:,24:]\n",
    "data2 = pd.concat([data2, data3], axis=1)\n",
    "#print(data1.columns, data2.columns)\n",
    "data1 = (data1 - data1.mean()) / data1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data1, data2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = ['sch_time_year','sch_time_month','sch_time_day','sch_time_hour','airline']#'origin_airport','dest_airport'\n",
    "data = pd.get_dummies(data, columns=one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport = ['origin_airport', 'dest_airport']\n",
    "data_1 = data[airport]\n",
    "data_2 = data.drop(airport, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_air = set(data_1.origin_airport) \n",
    "dest_air = set(data_1.dest_airport)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ori = {}\n",
    "dic_ori = dict(zip(ori_air, range(len(ori_air))))\n",
    "dic_dest = {}\n",
    "dic_dest = dict(zip(dest_air, range(len(dest_air))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "data_1.origin_airport = data_1.origin_airport.apply(lambda x: dic_ori[x])\n",
    "data_1.dest_airport = data_1.dest_airport.apply(lambda x: dic_dest[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data_1, data_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.info()\n",
    "#label.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, label_train, label_test = train_test_split(data, label, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_1 = data_train[airport]\n",
    "data_train_2 = data_train.drop(airport, axis=1)\n",
    "data_test_1 = data_test[airport]\n",
    "data_test_2 = data_test.drop(airport, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_airport</th>\n",
       "      <th>dest_airport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>592246</th>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429766</th>\n",
       "      <td>157</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324894</th>\n",
       "      <td>157</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389446</th>\n",
       "      <td>166</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064883</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         origin_airport  dest_airport\n",
       "592246               51            19\n",
       "429766              157           164\n",
       "324894              157            39\n",
       "389446              166           181\n",
       "3064883              40            50"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedding_size = 10\n",
    "InputSize_OriAir = len(ori_air)\n",
    "InputSize_DestAir = len(dest_air)\n",
    "InputSize_NoneAir = len(data_train_2.columns)\n",
    "\n",
    "inputs_ori = Input(shape=(1,))\n",
    "inputs_dest = Input(shape=(1,))\n",
    "inputs_noneair = Input(shape=(InputSize_NoneAir,))\n",
    "\n",
    "ori_embedding = Embedding(input_dim=InputSize_OriAir, output_dim=Embedding_size)(inputs_ori)\n",
    "dest_embedding = Embedding(input_dim=InputSize_DestAir, output_dim=Embedding_size)(inputs_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Dot(axes=2, normalize=True)([ori_embedding, dest_embedding])\n",
    "flatten_embedding = Flatten()(embedding)\n",
    "\n",
    "inputs = Concatenate(axis=1)([flatten_embedding, inputs_noneair])\n",
    "x = Dense(units=128, activation='tanh')(inputs)\n",
    "x = Dropout(0.1)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(units=64, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "outputs = Dense(units=2, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[inputs_ori, inputs_dest, inputs_noneair], outputs=[outputs])\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 288999 samples, validate on 72250 samples\n",
      "Epoch 1/100\n",
      "288999/288999 [==============================] - 10s 35us/step - loss: 0.6519 - acc: 0.6208 - val_loss: 0.6260 - val_acc: 0.6511\n",
      "Epoch 2/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.6302 - acc: 0.6459 - val_loss: 0.6154 - val_acc: 0.6601\n",
      "Epoch 3/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.6194 - acc: 0.6565 - val_loss: 0.6079 - val_acc: 0.6647\n",
      "Epoch 4/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.6115 - acc: 0.6632 - val_loss: 0.6032 - val_acc: 0.6695\n",
      "Epoch 5/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.6069 - acc: 0.6680 - val_loss: 0.6002 - val_acc: 0.6732\n",
      "Epoch 6/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.6030 - acc: 0.6716 - val_loss: 0.5973 - val_acc: 0.6745\n",
      "Epoch 7/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5999 - acc: 0.6735 - val_loss: 0.5951 - val_acc: 0.6760\n",
      "Epoch 8/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5978 - acc: 0.6754 - val_loss: 0.5937 - val_acc: 0.6769\n",
      "Epoch 9/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5961 - acc: 0.6772 - val_loss: 0.5924 - val_acc: 0.6781\n",
      "Epoch 10/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5944 - acc: 0.6790 - val_loss: 0.5911 - val_acc: 0.6787\n",
      "Epoch 11/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5928 - acc: 0.6805 - val_loss: 0.5900 - val_acc: 0.6808\n",
      "Epoch 12/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5914 - acc: 0.6810 - val_loss: 0.5892 - val_acc: 0.6814\n",
      "Epoch 13/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5903 - acc: 0.6813 - val_loss: 0.5882 - val_acc: 0.6818\n",
      "Epoch 14/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5892 - acc: 0.6835 - val_loss: 0.5873 - val_acc: 0.6830\n",
      "Epoch 15/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5886 - acc: 0.6841 - val_loss: 0.5869 - val_acc: 0.6841\n",
      "Epoch 16/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5873 - acc: 0.6854 - val_loss: 0.5863 - val_acc: 0.6839\n",
      "Epoch 17/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5870 - acc: 0.6855 - val_loss: 0.5859 - val_acc: 0.6846\n",
      "Epoch 18/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5859 - acc: 0.6862 - val_loss: 0.5851 - val_acc: 0.6854\n",
      "Epoch 19/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5851 - acc: 0.6872 - val_loss: 0.5851 - val_acc: 0.6850\n",
      "Epoch 20/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5848 - acc: 0.6880 - val_loss: 0.5845 - val_acc: 0.6861\n",
      "Epoch 21/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5842 - acc: 0.6882 - val_loss: 0.5841 - val_acc: 0.6859\n",
      "Epoch 22/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5838 - acc: 0.6881 - val_loss: 0.5837 - val_acc: 0.6869\n",
      "Epoch 23/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5827 - acc: 0.6894 - val_loss: 0.5832 - val_acc: 0.6871\n",
      "Epoch 24/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5826 - acc: 0.6897 - val_loss: 0.5828 - val_acc: 0.6883\n",
      "Epoch 25/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5820 - acc: 0.6908 - val_loss: 0.5827 - val_acc: 0.6885\n",
      "Epoch 26/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5817 - acc: 0.6919 - val_loss: 0.5824 - val_acc: 0.6888\n",
      "Epoch 27/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5812 - acc: 0.6912 - val_loss: 0.5820 - val_acc: 0.6888\n",
      "Epoch 28/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5807 - acc: 0.6915 - val_loss: 0.5819 - val_acc: 0.6896\n",
      "Epoch 29/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5802 - acc: 0.6921 - val_loss: 0.5811 - val_acc: 0.6914\n",
      "Epoch 30/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5799 - acc: 0.6934 - val_loss: 0.5811 - val_acc: 0.6898\n",
      "Epoch 31/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5791 - acc: 0.6931 - val_loss: 0.5808 - val_acc: 0.6905\n",
      "Epoch 32/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5792 - acc: 0.6933 - val_loss: 0.5810 - val_acc: 0.6911\n",
      "Epoch 33/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5788 - acc: 0.6942 - val_loss: 0.5805 - val_acc: 0.6909\n",
      "Epoch 34/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5786 - acc: 0.6932 - val_loss: 0.5801 - val_acc: 0.6917\n",
      "Epoch 35/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5783 - acc: 0.6945 - val_loss: 0.5802 - val_acc: 0.6914\n",
      "Epoch 36/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5781 - acc: 0.6951 - val_loss: 0.5798 - val_acc: 0.6922\n",
      "Epoch 37/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5779 - acc: 0.6943 - val_loss: 0.5796 - val_acc: 0.6922\n",
      "Epoch 38/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5773 - acc: 0.6959 - val_loss: 0.5794 - val_acc: 0.6925\n",
      "Epoch 39/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5768 - acc: 0.6957 - val_loss: 0.5794 - val_acc: 0.6929\n",
      "Epoch 40/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5768 - acc: 0.6955 - val_loss: 0.5793 - val_acc: 0.6928\n",
      "Epoch 41/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5766 - acc: 0.6961 - val_loss: 0.5786 - val_acc: 0.6935\n",
      "Epoch 42/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5760 - acc: 0.6970 - val_loss: 0.5791 - val_acc: 0.6927\n",
      "Epoch 43/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5760 - acc: 0.6975 - val_loss: 0.5785 - val_acc: 0.6938\n",
      "Epoch 44/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5750 - acc: 0.6971 - val_loss: 0.5784 - val_acc: 0.6941\n",
      "Epoch 45/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5752 - acc: 0.6971 - val_loss: 0.5780 - val_acc: 0.6939\n",
      "Epoch 46/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5753 - acc: 0.6975 - val_loss: 0.5780 - val_acc: 0.6958\n",
      "Epoch 47/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5747 - acc: 0.6977 - val_loss: 0.5776 - val_acc: 0.6948\n",
      "Epoch 48/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5740 - acc: 0.6991 - val_loss: 0.5775 - val_acc: 0.6951\n",
      "Epoch 49/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5742 - acc: 0.6992 - val_loss: 0.5771 - val_acc: 0.6958\n",
      "Epoch 50/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5741 - acc: 0.6987 - val_loss: 0.5772 - val_acc: 0.6961\n",
      "Epoch 51/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5738 - acc: 0.6993 - val_loss: 0.5773 - val_acc: 0.6956\n",
      "Epoch 52/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5735 - acc: 0.6999 - val_loss: 0.5770 - val_acc: 0.6965\n",
      "Epoch 53/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5734 - acc: 0.7001 - val_loss: 0.5765 - val_acc: 0.6960\n",
      "Epoch 54/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5729 - acc: 0.7000 - val_loss: 0.5762 - val_acc: 0.6971\n",
      "Epoch 55/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5731 - acc: 0.6994 - val_loss: 0.5766 - val_acc: 0.6962\n",
      "Epoch 56/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5729 - acc: 0.6999 - val_loss: 0.5764 - val_acc: 0.6964\n",
      "Epoch 57/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5725 - acc: 0.7008 - val_loss: 0.5762 - val_acc: 0.6960\n",
      "Epoch 58/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5723 - acc: 0.7006 - val_loss: 0.5763 - val_acc: 0.6971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5722 - acc: 0.7012 - val_loss: 0.5762 - val_acc: 0.6973\n",
      "Epoch 60/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5718 - acc: 0.7017 - val_loss: 0.5762 - val_acc: 0.6969\n",
      "Epoch 61/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5713 - acc: 0.7017 - val_loss: 0.5761 - val_acc: 0.6973\n",
      "Epoch 62/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5716 - acc: 0.7011 - val_loss: 0.5759 - val_acc: 0.6967\n",
      "Epoch 63/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5712 - acc: 0.7014 - val_loss: 0.5755 - val_acc: 0.6979\n",
      "Epoch 64/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5706 - acc: 0.7027 - val_loss: 0.5756 - val_acc: 0.6986\n",
      "Epoch 65/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5710 - acc: 0.7023 - val_loss: 0.5752 - val_acc: 0.6978\n",
      "Epoch 66/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5706 - acc: 0.7025 - val_loss: 0.5752 - val_acc: 0.6983\n",
      "Epoch 67/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5708 - acc: 0.7023 - val_loss: 0.5752 - val_acc: 0.6987\n",
      "Epoch 68/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5703 - acc: 0.7022 - val_loss: 0.5751 - val_acc: 0.6985\n",
      "Epoch 69/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5704 - acc: 0.7029 - val_loss: 0.5752 - val_acc: 0.6982\n",
      "Epoch 70/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5701 - acc: 0.7025 - val_loss: 0.5749 - val_acc: 0.6983\n",
      "Epoch 71/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5700 - acc: 0.7027 - val_loss: 0.5747 - val_acc: 0.6976\n",
      "Epoch 72/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5696 - acc: 0.7032 - val_loss: 0.5746 - val_acc: 0.6984\n",
      "Epoch 73/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5691 - acc: 0.7038 - val_loss: 0.5747 - val_acc: 0.6986\n",
      "Epoch 74/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5697 - acc: 0.7030 - val_loss: 0.5746 - val_acc: 0.6988\n",
      "Epoch 75/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5687 - acc: 0.7041 - val_loss: 0.5747 - val_acc: 0.6993\n",
      "Epoch 76/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5689 - acc: 0.7038 - val_loss: 0.5745 - val_acc: 0.6986\n",
      "Epoch 77/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5690 - acc: 0.7039 - val_loss: 0.5744 - val_acc: 0.6989\n",
      "Epoch 78/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5687 - acc: 0.7041 - val_loss: 0.5742 - val_acc: 0.6983\n",
      "Epoch 79/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5683 - acc: 0.7045 - val_loss: 0.5742 - val_acc: 0.6984\n",
      "Epoch 80/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5685 - acc: 0.7046 - val_loss: 0.5743 - val_acc: 0.6986\n",
      "Epoch 81/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5683 - acc: 0.7045 - val_loss: 0.5741 - val_acc: 0.6992\n",
      "Epoch 82/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5680 - acc: 0.7052 - val_loss: 0.5740 - val_acc: 0.6994\n",
      "Epoch 83/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5681 - acc: 0.7044 - val_loss: 0.5738 - val_acc: 0.6996\n",
      "Epoch 84/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5680 - acc: 0.7047 - val_loss: 0.5738 - val_acc: 0.6995\n",
      "Epoch 85/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5682 - acc: 0.7050 - val_loss: 0.5739 - val_acc: 0.7002\n",
      "Epoch 86/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5677 - acc: 0.7049 - val_loss: 0.5739 - val_acc: 0.6991\n",
      "Epoch 87/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5675 - acc: 0.7049 - val_loss: 0.5736 - val_acc: 0.6997\n",
      "Epoch 88/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5676 - acc: 0.7053 - val_loss: 0.5734 - val_acc: 0.6992\n",
      "Epoch 89/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5672 - acc: 0.7054 - val_loss: 0.5736 - val_acc: 0.7000\n",
      "Epoch 90/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5670 - acc: 0.7058 - val_loss: 0.5736 - val_acc: 0.6995\n",
      "Epoch 91/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5669 - acc: 0.7062 - val_loss: 0.5736 - val_acc: 0.7002\n",
      "Epoch 92/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5674 - acc: 0.7055 - val_loss: 0.5732 - val_acc: 0.7010\n",
      "Epoch 93/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5666 - acc: 0.7061 - val_loss: 0.5734 - val_acc: 0.7006\n",
      "Epoch 94/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5664 - acc: 0.7066 - val_loss: 0.5734 - val_acc: 0.7007\n",
      "Epoch 95/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5664 - acc: 0.7058 - val_loss: 0.5732 - val_acc: 0.7007\n",
      "Epoch 96/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5665 - acc: 0.7061 - val_loss: 0.5731 - val_acc: 0.7007\n",
      "Epoch 97/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5665 - acc: 0.7066 - val_loss: 0.5728 - val_acc: 0.7005\n",
      "Epoch 98/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5660 - acc: 0.7057 - val_loss: 0.5730 - val_acc: 0.6999\n",
      "Epoch 99/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5662 - acc: 0.7066 - val_loss: 0.5728 - val_acc: 0.7005\n",
      "Epoch 100/100\n",
      "288999/288999 [==============================] - 9s 31us/step - loss: 0.5664 - acc: 0.7061 - val_loss: 0.5729 - val_acc: 0.7007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc78a6a17b8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[data_train_1.origin_airport, data_train_1.dest_airport, data_train_2],\n",
    "          y=label_train,\n",
    "          epochs=100,\n",
    "          batch_size=256,\n",
    "          #verbose=2,\n",
    "          validation_split=0.2\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90313/90313 [==============================] - 0s 2us/step\n",
      "Test score: 0.5728943943977356\n",
      "Test accuracy: 0.7011061310768127\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x=[data_test_1.origin_airport, data_test_1.dest_airport, data_test_2],\n",
    "                       y=label_test,\n",
    "                       batch_size=len(data_test))\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
