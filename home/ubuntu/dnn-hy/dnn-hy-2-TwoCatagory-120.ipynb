{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dnn-hy 实验二 by 孟\n",
    "\n",
    "\n",
    "基础航班延误模型，2分类任务，之前下采样【-500，30】，【30，-】，现在下采样【-500，120】，【120，-】相比于之前的二分类任务，准确率有明显提升。\n",
    "\n",
    "之前 66.5%   现在 70.7%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from keras import initializers\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_feather('/home/ubuntu/data/flight_data_7_18.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['feat1'] = data['delay_cat'].map(lambda x: 1 if x == '[-500,30)' or x == '[30,60)' or x == '[60,90)' or x == '[90,120)' else 0)\n",
    "data['feat2'] = data['feat1'].map(lambda x: 1-x)\n",
    "data = data.drop(['delay_cat'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "#data = shuffle(data)\n",
    "data = data.sample(frac=0.5)\n",
    "#print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3296578\n",
       "0     226324\n",
       "Name: feat1, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feat1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "data_majority = data[data.feat1==1]\n",
    "data_minority = data[data.feat1==0]\n",
    "data_majority_downsampled = resample(data_majority,\n",
    "                                     replace=False,    # sample without replacement\n",
    "                                     n_samples=226020,     # to match minority class\n",
    "                                     random_state=1) # reproducible results\n",
    "data_downsampled = pd.concat([data_majority_downsampled, data_minority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sch_time_year'] = data['sch_dep_time'].map(lambda x: x.year)\n",
    "data['sch_time_month'] = data['sch_dep_time'].map(lambda x: x.month)\n",
    "data['sch_time_day'] = data['sch_dep_time'].map(lambda x: x.day)\n",
    "data['sch_time_hour'] = data['sch_dep_time'].map(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sch_time_year'] = (data['sch_time_year'].map(lambda x: int(str(x)[2:])))\n",
    "month_num = {1:6, 2:2, 3:2, 4:5, 5:0, 6:3, 7:5, 8:1, 9:4, 10:6, 11:2, 12:4}\n",
    "data['year_num'] = data['sch_time_year'].map(lambda x: (int(x / 4) + x) % 7)\n",
    "data['month_num']=  data['sch_time_month'].map(lambda x: month_num[x])\n",
    "data['day_num'] = data['sch_time_day']\n",
    "data['sch_time_day'] = data.apply(lambda x: (x['year_num'] + x['month_num'] + x['day_num'])%7, axis=1)\n",
    "time_drop = ['year_num', 'month_num', 'day_num']\n",
    "data = data.drop(time_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sch_time_hour'] = data['sch_time_hour'].map(lambda x: 24 if x==0 else x)\n",
    "for i in range(8):  #每3个小时一个区间\n",
    "    data['sch_time_hour'] = data['sch_time_hour'].map(lambda x: 0+i if x>0+3*i and x<=3+3*i else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = ['feat1','feat2']\n",
    "label = data[lb]\n",
    "data = data.drop(lb, axis=1)\n",
    "data = data.drop('sch_dep_time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.iloc[:,3:24]\n",
    "\n",
    "data2 = data.iloc[:,0:3]\n",
    "data3 = data.iloc[:,24:]\n",
    "data2 = pd.concat([data2, data3], axis=1)\n",
    "#print(data1.columns, data2.columns)\n",
    "data1 = (data1 - data1.mean()) / data1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data1, data2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data\n",
    "label_train = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = ['sch_time_year','sch_time_month','sch_time_day','sch_time_hour','airline','origin_airport','dest_airport']\n",
    "data_train = pd.get_dummies(data_train, columns=one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(data_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = clf.feature_importances_ \n",
    "for i in range(len(importance)):\n",
    "    if importance[i]>=1e-1 or importance[i]<=1e-5:\n",
    "        importance[i] = 0\n",
    "feature_importance_index = np.where(importance!=0)\n",
    "#feature_importance_index\n",
    "#len(feature_importance_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_index = np.squeeze(np.array(feature_importance_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, label_train, label_test = train_test_split(data_train, label_train, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "input_size = len(data_train.columns)\n",
    "\n",
    "inputs = Input(shape=(input_size,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "#x = Dropout(0.5)(x)\n",
    "#x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "#x = Dense(128, activation='relu')(x)\n",
    "#x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(2, activation='softmax', name='ou')(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 289500 samples, validate on 72375 samples\n",
      "Epoch 1/100\n",
      "289500/289500 [==============================] - 8s 28us/step - loss: 0.6634 - acc: 0.5991 - val_loss: 0.6332 - val_acc: 0.6460\n",
      "Epoch 2/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.6364 - acc: 0.6406 - val_loss: 0.6197 - val_acc: 0.6578\n",
      "Epoch 3/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.6252 - acc: 0.6528 - val_loss: 0.6139 - val_acc: 0.6629\n",
      "Epoch 4/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.6196 - acc: 0.6584 - val_loss: 0.6101 - val_acc: 0.6663\n",
      "Epoch 5/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.6155 - acc: 0.6619 - val_loss: 0.6070 - val_acc: 0.6690\n",
      "Epoch 6/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.6117 - acc: 0.6658 - val_loss: 0.6040 - val_acc: 0.6722\n",
      "Epoch 7/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.6088 - acc: 0.6688 - val_loss: 0.6017 - val_acc: 0.6747\n",
      "Epoch 8/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.6060 - acc: 0.6722 - val_loss: 0.5987 - val_acc: 0.6776\n",
      "Epoch 9/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.6029 - acc: 0.6760 - val_loss: 0.5964 - val_acc: 0.6796\n",
      "Epoch 10/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.6005 - acc: 0.6784 - val_loss: 0.5942 - val_acc: 0.6816\n",
      "Epoch 11/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5976 - acc: 0.6807 - val_loss: 0.5920 - val_acc: 0.6844\n",
      "Epoch 12/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5956 - acc: 0.6839 - val_loss: 0.5904 - val_acc: 0.6859\n",
      "Epoch 13/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5939 - acc: 0.6845 - val_loss: 0.5887 - val_acc: 0.6868\n",
      "Epoch 14/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5919 - acc: 0.6873 - val_loss: 0.5874 - val_acc: 0.6885\n",
      "Epoch 15/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5898 - acc: 0.6888 - val_loss: 0.5861 - val_acc: 0.6905\n",
      "Epoch 16/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5879 - acc: 0.6908 - val_loss: 0.5850 - val_acc: 0.6912\n",
      "Epoch 17/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5869 - acc: 0.6920 - val_loss: 0.5838 - val_acc: 0.6925\n",
      "Epoch 18/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5852 - acc: 0.6942 - val_loss: 0.5827 - val_acc: 0.6939\n",
      "Epoch 19/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5835 - acc: 0.6955 - val_loss: 0.5816 - val_acc: 0.6950\n",
      "Epoch 20/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5825 - acc: 0.6963 - val_loss: 0.5809 - val_acc: 0.6954\n",
      "Epoch 21/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5815 - acc: 0.6966 - val_loss: 0.5802 - val_acc: 0.6962\n",
      "Epoch 22/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5801 - acc: 0.6979 - val_loss: 0.5795 - val_acc: 0.6970\n",
      "Epoch 23/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5782 - acc: 0.6995 - val_loss: 0.5787 - val_acc: 0.6964\n",
      "Epoch 24/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5777 - acc: 0.7005 - val_loss: 0.5781 - val_acc: 0.6976\n",
      "Epoch 25/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5765 - acc: 0.7018 - val_loss: 0.5776 - val_acc: 0.6985\n",
      "Epoch 26/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5757 - acc: 0.7019 - val_loss: 0.5769 - val_acc: 0.6996\n",
      "Epoch 27/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5747 - acc: 0.7029 - val_loss: 0.5767 - val_acc: 0.6990\n",
      "Epoch 28/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5736 - acc: 0.7042 - val_loss: 0.5761 - val_acc: 0.6995\n",
      "Epoch 29/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5725 - acc: 0.7047 - val_loss: 0.5755 - val_acc: 0.7001\n",
      "Epoch 30/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5724 - acc: 0.7054 - val_loss: 0.5750 - val_acc: 0.7002\n",
      "Epoch 31/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5710 - acc: 0.7063 - val_loss: 0.5746 - val_acc: 0.7017\n",
      "Epoch 32/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5698 - acc: 0.7066 - val_loss: 0.5743 - val_acc: 0.7013\n",
      "Epoch 33/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5696 - acc: 0.7077 - val_loss: 0.5737 - val_acc: 0.7022\n",
      "Epoch 34/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5683 - acc: 0.7084 - val_loss: 0.5738 - val_acc: 0.7017\n",
      "Epoch 35/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5681 - acc: 0.7083 - val_loss: 0.5734 - val_acc: 0.7018\n",
      "Epoch 36/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5670 - acc: 0.7095 - val_loss: 0.5732 - val_acc: 0.7027\n",
      "Epoch 37/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5668 - acc: 0.7093 - val_loss: 0.5730 - val_acc: 0.7033\n",
      "Epoch 38/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5661 - acc: 0.7106 - val_loss: 0.5729 - val_acc: 0.7033\n",
      "Epoch 39/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5650 - acc: 0.7111 - val_loss: 0.5729 - val_acc: 0.7025\n",
      "Epoch 40/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5644 - acc: 0.7115 - val_loss: 0.5723 - val_acc: 0.7029\n",
      "Epoch 41/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5638 - acc: 0.7123 - val_loss: 0.5723 - val_acc: 0.7027\n",
      "Epoch 42/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5630 - acc: 0.7128 - val_loss: 0.5718 - val_acc: 0.7033\n",
      "Epoch 43/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5626 - acc: 0.7121 - val_loss: 0.5718 - val_acc: 0.7038\n",
      "Epoch 44/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5625 - acc: 0.7141 - val_loss: 0.5715 - val_acc: 0.7035\n",
      "Epoch 45/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5618 - acc: 0.7137 - val_loss: 0.5713 - val_acc: 0.7039\n",
      "Epoch 46/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5611 - acc: 0.7144 - val_loss: 0.5714 - val_acc: 0.7038\n",
      "Epoch 47/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5607 - acc: 0.7153 - val_loss: 0.5712 - val_acc: 0.7045\n",
      "Epoch 48/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5602 - acc: 0.7154 - val_loss: 0.5711 - val_acc: 0.7043\n",
      "Epoch 49/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5600 - acc: 0.7155 - val_loss: 0.5710 - val_acc: 0.7043\n",
      "Epoch 50/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5595 - acc: 0.7167 - val_loss: 0.5711 - val_acc: 0.7039\n",
      "Epoch 51/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5590 - acc: 0.7166 - val_loss: 0.5707 - val_acc: 0.7049\n",
      "Epoch 52/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5575 - acc: 0.7174 - val_loss: 0.5706 - val_acc: 0.7048\n",
      "Epoch 53/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5578 - acc: 0.7168 - val_loss: 0.5706 - val_acc: 0.7044\n",
      "Epoch 54/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5578 - acc: 0.7171 - val_loss: 0.5707 - val_acc: 0.7042\n",
      "Epoch 55/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5571 - acc: 0.7175 - val_loss: 0.5705 - val_acc: 0.7045\n",
      "Epoch 56/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5564 - acc: 0.7181 - val_loss: 0.5705 - val_acc: 0.7047\n",
      "Epoch 57/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5563 - acc: 0.7186 - val_loss: 0.5704 - val_acc: 0.7051\n",
      "Epoch 58/100\n",
      "289500/289500 [==============================] - 7s 26us/step - loss: 0.5556 - acc: 0.7189 - val_loss: 0.5706 - val_acc: 0.7049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "289500/289500 [==============================] - 8s 29us/step - loss: 0.5560 - acc: 0.7188 - val_loss: 0.5704 - val_acc: 0.7046\n",
      "Epoch 60/100\n",
      "289500/289500 [==============================] - 9s 30us/step - loss: 0.5549 - acc: 0.7189 - val_loss: 0.5700 - val_acc: 0.7055\n",
      "Epoch 61/100\n",
      "289500/289500 [==============================] - 9s 30us/step - loss: 0.5549 - acc: 0.7198 - val_loss: 0.5700 - val_acc: 0.7056\n",
      "Epoch 62/100\n",
      "289500/289500 [==============================] - 8s 29us/step - loss: 0.5544 - acc: 0.7204 - val_loss: 0.5701 - val_acc: 0.7048\n",
      "Epoch 63/100\n",
      "289500/289500 [==============================] - 8s 29us/step - loss: 0.5540 - acc: 0.7200 - val_loss: 0.5703 - val_acc: 0.7063\n",
      "Epoch 64/100\n",
      "289500/289500 [==============================] - 9s 30us/step - loss: 0.5534 - acc: 0.7202 - val_loss: 0.5701 - val_acc: 0.7055\n",
      "Epoch 65/100\n",
      "289500/289500 [==============================] - 8s 29us/step - loss: 0.5537 - acc: 0.7202 - val_loss: 0.5701 - val_acc: 0.7053\n",
      "Epoch 66/100\n",
      "289500/289500 [==============================] - 9s 30us/step - loss: 0.5533 - acc: 0.7204 - val_loss: 0.5700 - val_acc: 0.7056\n",
      "Epoch 67/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5535 - acc: 0.7199 - val_loss: 0.5700 - val_acc: 0.7060\n",
      "Epoch 68/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5528 - acc: 0.7217 - val_loss: 0.5702 - val_acc: 0.7060\n",
      "Epoch 69/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5524 - acc: 0.7215 - val_loss: 0.5699 - val_acc: 0.7063\n",
      "Epoch 70/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5520 - acc: 0.7219 - val_loss: 0.5699 - val_acc: 0.7059\n",
      "Epoch 71/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5519 - acc: 0.7219 - val_loss: 0.5698 - val_acc: 0.7062\n",
      "Epoch 72/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5512 - acc: 0.7228 - val_loss: 0.5699 - val_acc: 0.7066\n",
      "Epoch 73/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5515 - acc: 0.7229 - val_loss: 0.5701 - val_acc: 0.7066\n",
      "Epoch 74/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5511 - acc: 0.7224 - val_loss: 0.5702 - val_acc: 0.7058\n",
      "Epoch 75/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5504 - acc: 0.7229 - val_loss: 0.5704 - val_acc: 0.7063\n",
      "Epoch 76/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5507 - acc: 0.7231 - val_loss: 0.5699 - val_acc: 0.7067\n",
      "Epoch 77/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5508 - acc: 0.7224 - val_loss: 0.5697 - val_acc: 0.7064\n",
      "Epoch 78/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5512 - acc: 0.7226 - val_loss: 0.5696 - val_acc: 0.7073\n",
      "Epoch 79/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5502 - acc: 0.7232 - val_loss: 0.5700 - val_acc: 0.7064\n",
      "Epoch 80/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5500 - acc: 0.7230 - val_loss: 0.5699 - val_acc: 0.7064\n",
      "Epoch 81/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5496 - acc: 0.7230 - val_loss: 0.5697 - val_acc: 0.7067\n",
      "Epoch 82/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5495 - acc: 0.7239 - val_loss: 0.5695 - val_acc: 0.7074\n",
      "Epoch 83/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5493 - acc: 0.7243 - val_loss: 0.5698 - val_acc: 0.7066\n",
      "Epoch 84/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5491 - acc: 0.7243 - val_loss: 0.5700 - val_acc: 0.7071\n",
      "Epoch 85/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5491 - acc: 0.7235 - val_loss: 0.5700 - val_acc: 0.7070\n",
      "Epoch 86/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5483 - acc: 0.7237 - val_loss: 0.5701 - val_acc: 0.7062\n",
      "Epoch 87/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5486 - acc: 0.7243 - val_loss: 0.5698 - val_acc: 0.7063\n",
      "Epoch 88/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5486 - acc: 0.7242 - val_loss: 0.5699 - val_acc: 0.7073\n",
      "Epoch 89/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5482 - acc: 0.7248 - val_loss: 0.5701 - val_acc: 0.7063\n",
      "Epoch 90/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5491 - acc: 0.7235 - val_loss: 0.5699 - val_acc: 0.7078\n",
      "Epoch 91/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5479 - acc: 0.7244 - val_loss: 0.5700 - val_acc: 0.7076\n",
      "Epoch 92/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5478 - acc: 0.7254 - val_loss: 0.5698 - val_acc: 0.7079\n",
      "Epoch 93/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5477 - acc: 0.7255 - val_loss: 0.5697 - val_acc: 0.7078\n",
      "Epoch 94/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5476 - acc: 0.7253 - val_loss: 0.5698 - val_acc: 0.7080\n",
      "Epoch 95/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5476 - acc: 0.7245 - val_loss: 0.5697 - val_acc: 0.7085\n",
      "Epoch 96/100\n",
      "289500/289500 [==============================] - 7s 25us/step - loss: 0.5473 - acc: 0.7259 - val_loss: 0.5699 - val_acc: 0.7078\n",
      "Epoch 97/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5469 - acc: 0.7256 - val_loss: 0.5698 - val_acc: 0.7084\n",
      "Epoch 98/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5467 - acc: 0.7258 - val_loss: 0.5699 - val_acc: 0.7076\n",
      "Epoch 99/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5466 - acc: 0.7260 - val_loss: 0.5701 - val_acc: 0.7080\n",
      "Epoch 100/100\n",
      "289500/289500 [==============================] - 7s 24us/step - loss: 0.5461 - acc: 0.7264 - val_loss: 0.5700 - val_acc: 0.7082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6019da6208>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=data_train,\n",
    "          y=label_train,\n",
    "          epochs=100,\n",
    "          batch_size=256,\n",
    "          #verbose=2,\n",
    "          validation_split=0.2\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90469/90469 [==============================] - 0s 4us/step\n",
      "Test score: 0.5667464733123779\n",
      "Test accuracy: 0.7079331278800964\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x=data_test,\n",
    "                       y=label_test,\n",
    "                       batch_size=len(data_test))\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
